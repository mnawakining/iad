{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at http://pobeda2.ru/component/k2/item/4769\n",
      "Error at http://pobeda2.ru/component/k2/item/4826\n",
      "Error at http://pobeda2.ru/component/k2/item/4827\n",
      "Error at http://pobeda2.ru/component/k2/item/4882\n",
      "Error at http://pobeda2.ru/component/k2/item/4891\n",
      "Error at http://pobeda2.ru/component/k2/item/4902\n",
      "Error at http://pobeda2.ru/component/k2/item/4903\n",
      "Error at http://pobeda2.ru/component/k2/item/4904\n",
      "Error at http://pobeda2.ru/component/k2/item/4905\n",
      "Error at http://pobeda2.ru/component/k2/item/4907\n",
      "Error at http://pobeda2.ru/component/k2/item/4939\n",
      "Error at http://pobeda2.ru/component/k2/item/4940\n",
      "Error at http://pobeda2.ru/component/k2/item/4941\n",
      "Error at http://pobeda2.ru/component/k2/item/4958\n",
      "Error at http://pobeda2.ru/component/k2/item/4960\n",
      "Error at http://pobeda2.ru/component/k2/item/5016\n"
     ]
    }
   ],
   "source": [
    "import urllib.request as ur \n",
    "\n",
    "commonUrl = 'http://pobeda2.ru/component/k2/item/' #адрес выбранной газеты (\"Победа\") \n",
    "\n",
    "def download_pages(commonUrl): #функция, выгружающая новости по принципу краулера (обходом по номеру страницы) \n",
    "    html_dict = {} \n",
    "    for i in range(4700, 5049):#диапазон страниц \n",
    "        pageUrl = commonUrl + str(i) \n",
    "        try: \n",
    "            page = ur.urlopen(pageUrl) \n",
    "            html = page.read().decode() \n",
    "            html_dict[pageUrl] = html \n",
    "        except: \n",
    "            print('Error at', pageUrl) \n",
    "    return html_dict \n",
    "\n",
    "html_dict = download_pages(commonUrl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regTag = re.compile('<.*?>', re.DOTALL)  # это рег. выражение находит все тэги\n",
    "regScript = re.compile('<script>.*?</script>', re.DOTALL) # все скрипты\n",
    "regComment = re.compile('<!--.*?-->', re.DOTALL)  # все комментарии\n",
    "regText = re.compile('<div class=\"itemIntroText\">.*?<div class=\"clr\"></div>', re.DOTALL) #текст статьи\n",
    "regTitle = re.compile(r'<meta name=\"title\" content=\"(.*?)\" />', re.DOTALL) #рег. выр для поиска заголовка\n",
    "regData = re.compile(r'<div class=\"itemDate.*?div>', re.DOTALL) #рег.выражение для поиска даты\n",
    "regCat = re.compile('Опубликовано в</span>.*?</a>', re.DOTALL) #рег выражение для поиска категории\n",
    "regEntr = re.compile('\\r[\\n|\\s|\\t]+\\r', re.DOTALL) #доп. очистка текста от множественных пробелов, табуляций и переноса строки\n",
    "\n",
    "def clean_html(html, url): #функция для извлечения текста и данных для metadata.csv из html\n",
    "    \n",
    "    #извлекаем и очищаем заголовок, дату , год, категорию и текст\n",
    "\n",
    "    title = regTitle.search(html).group(0) \n",
    "    title = re.sub(r'<meta name=\"title\" content=\"|\" />','', title)\n",
    "\n",
    "    \n",
    "    data = regData.search(html).group(0)    \n",
    "    data = re.search('\\d{2}\\.\\d{2}\\.\\d{2}', data).group(0)\n",
    "    data = data[:6] + '20' + data[-2:] #изменяем формат с dd.mm.yy на dd.mm.yyyy\n",
    "\n",
    "    year = data[-4:]\n",
    "       \n",
    "    cat = regCat.search(html).group(0)\n",
    "    cat = regTag.sub('', cat)\n",
    "    cat = re.sub(r'Опубликовано в|\\t|\\n','',cat)\n",
    "    \n",
    "    text = regText.search(html).group(0)\n",
    "    \n",
    "    clean_t = regScript.sub('', text)\n",
    "    clean_t = regComment.sub('', clean_t)\n",
    "    clean_t = regTag.sub('', clean_t)\n",
    "    clean_t = regEntr.sub('', clean_t)\n",
    "\n",
    "    \n",
    "    words = clean_t.strip().split()#разбиваем текст статьи по пробелам \n",
    "    txt_len = len(words)#и считаем сколько слов в данной стратье\n",
    "    \n",
    "    clean_t ='@au ' + 'pobeda' + '\\n@ti ' + title + '\\n@da '+ data + '\\n@topic '+ cat + '\\n@url ' + url + '\\n' + clean_t #на страницах \n",
    "                #газеты в разделе Автор всегда будет написано pobeda\n",
    "    clean_t = clean_t.strip() #удаляем пробелы справа и слева\n",
    "    \n",
    "    return clean_t, title, data, year, cat, txt_len\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def mystem_dir(path_, year, data,  f): #функция создающая файлы размеченные при помощи mysterm\n",
    "    \n",
    "    out1 ='E:\\\\gazeta\\\\mystem-plain\\\\' + year + '\\\\' + data[3:5] \n",
    "    out2 ='E:\\\\gazeta\\\\mystem-xml\\\\' + year + '\\\\' + data[3:5] \n",
    "    try: \n",
    "        os.makedirs(out1)\n",
    "\n",
    "    except: pass\n",
    "    try:\n",
    "        os.makedirs(out2)\n",
    "    except: pass\n",
    "\n",
    "    os.system('E:\\\\mystem.exe  -nig ' + path_ + '\\\\' + f + ' ' + out1 + '\\\\'+ f)\n",
    "    \n",
    "    os.system('E:\\\\mystem.exe -cgin --format xml ' + path_ + '\\\\' + f + ' ' + out2 + '\\\\'+ f[:-4] + '.xml')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "\n",
    "\n",
    "\n",
    "def make_files(text, data, year): #функция для содание файла .txt и дикертории к нему\n",
    "    path_ = 'E:\\\\gazeta\\\\plain\\\\' + year + '\\\\' + data[3:5] \n",
    "    try:\n",
    "        os.makedirs(path_)\n",
    "    except: \n",
    "        pass    \n",
    "    \n",
    "    i = len(os.listdir(path = path_)) + 1\n",
    "    \n",
    "    f = codecs.open(path_ + '\\\\' + 'stat' + str(i)  + '.txt', 'w', 'utf-8')#открываем файл для записи в кодировке utf-8 ()\n",
    "    f.write(text)\n",
    "    f.close()\n",
    "    \n",
    "    mystem_dir(path_, year, data, 'stat' + str(i)  + '.txt')\n",
    "    \n",
    "    return path_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metadata = pd.DataFrame(columns = ['path' , 'author', 'sex', 'birthday', 'header','created',\n",
    "                                  'sphere', 'genre_fi', 'type','topic','chronotop','style',\n",
    "                                  'audience_age','audience_level', 'audience_size', 'source',\n",
    "                                   'publication','publisher','publ_year','medium','country','region','language']) #создаем DataFram\n",
    "                                                                                        #который выгрузим далее как csv файл\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество слов всего:  118417\n"
     ]
    }
   ],
   "source": [
    "count_words = 0\n",
    "for url in html_dict.keys(): #проходимся по всем выгруж текстам \n",
    "    try:\n",
    "        text , title, data, year, cat, txt_len = clean_html(html_dict[url], url)\n",
    "        path_ = make_files(text, data, year)      \n",
    "        count_words = count_words + txt_len \n",
    "        metadata.loc[len(metadata)] = [path_,'pobeda', None, None, title , data,\n",
    "                                       'публицистика', None, None , cat, None, \n",
    "                                       'нейтральный', 'н-возраст', 'н-уровень',\n",
    "                                       'районная', url, 'Победа', None,\n",
    "                                       year, 'газета',  'Россия', 'Удмуртская республика', 'ru']\n",
    "    except: pass \n",
    "    \n",
    "    \n",
    "\n",
    "print('Количество слов всего: ', count_words)\n",
    "\n",
    "metadata.to_csv('E:\\\\gazeta\\\\metadata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
